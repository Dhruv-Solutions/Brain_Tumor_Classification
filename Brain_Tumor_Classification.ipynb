{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:14:03.974729Z",
     "start_time": "2025-07-24T15:14:03.969043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "\n",
    "BASE = \"/Users/dhruvsharma/Downloads/DS - Brain Tumor MRI Image Classification/Tumour\"\n",
    "splits = [\"train\", \"valid\", \"test\"]\n",
    "for split in splits:\n",
    "    path = os.path.join(BASE, split)\n",
    "    counts = Counter(d for d in os.listdir(path) if os.path.isdir(os.path.join(path,d)))\n",
    "    print(f\"{split.upper():6}\", counts)\n",
    "\n",
    "    # show one sample\n",
    "    cls = next(iter(counts))\n",
    "    img = Image.open(os.path.join(path, cls, os.listdir(os.path.join(path,cls))[0]))\n",
    "    print(f\"  Sample {split}/{cls} → size={img.size}, mode={img.mode}\")\n"
   ],
   "id": "1d0028e0c1f156ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN  Counter({'pituitary': 1, 'No Tumor': 1, 'glioma': 1, 'meningioma': 1})\n",
      "  Sample train/pituitary → size=(640, 640), mode=RGB\n",
      "VALID  Counter({'pituitary': 1, 'No Tumor': 1, 'glioma': 1, 'meningioma': 1})\n",
      "  Sample valid/pituitary → size=(640, 640), mode=RGB\n",
      "TEST   Counter({'pituitary': 1, 'No Tumor': 1, 'glioma': 1, 'meningioma': 1})\n",
      "  Sample test/pituitary → size=(640, 640), mode=RGB\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:14:03.983351Z",
     "start_time": "2025-07-24T15:14:03.980587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data Preprocessing functions\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE = (224,224)\n",
    "\n",
    "def preprocess_image(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "def make_dataset(split_dir, batch=32, augment=False):\n",
    "    ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        split_dir,\n",
    "        image_size=IMG_SIZE,\n",
    "        batch_size=batch,\n",
    "        label_mode='categorical'\n",
    "    )\n",
    "    return ds\n"
   ],
   "id": "ca695cbdac0499a7",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:14:04.005467Z",
     "start_time": "2025-07-24T15:14:03.995310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data Augmentation\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomTranslation(0.1,0.1),\n",
    "])\n"
   ],
   "id": "aa1ad017345ab986",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:14:04.011369Z",
     "start_time": "2025-07-24T15:14:04.008611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_custom_cnn(input_shape=(224,224,3), num_classes=4):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(input_shape),\n",
    "        layers.Conv2D(32,3, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPool2D(),\n",
    "        layers.Conv2D(64,3, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPool2D(),\n",
    "        layers.Conv2D(128,3, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPool2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ],
   "id": "1aab1ca7c0be17d8",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:16:38.397843Z",
     "start_time": "2025-07-24T15:14:04.015080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from preprocessing import make_dataset\n",
    "#from model_custom import build_custom_cnn\n",
    "\n",
    "train_ds = make_dataset(os.path.join(BASE,\"train\"), batch=32, augment=True)\n",
    "val_ds   = make_dataset(os.path.join(BASE,\"valid\"), batch=32)\n",
    "\n",
    "model = build_custom_cnn()\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint(\"models/custom_cnn.keras\", save_best_only=True)\n",
    "]\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=50, callbacks=callbacks)\n"
   ],
   "id": "b2f583ac924338be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1695 files belonging to 4 classes.\n",
      "Found 502 files belonging to 4 classes.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 20:44:04.593388: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 227ms/step - accuracy: 0.6695 - loss: 1.0819 - val_accuracy: 0.1972 - val_loss: 10.1269\n",
      "Epoch 2/50\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 225ms/step - accuracy: 0.8428 - loss: 0.4722 - val_accuracy: 0.4841 - val_loss: 1.2969\n",
      "Epoch 3/50\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 220ms/step - accuracy: 0.9033 - loss: 0.2660 - val_accuracy: 0.5996 - val_loss: 1.0097\n",
      "Epoch 4/50\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 219ms/step - accuracy: 0.9179 - loss: 0.2126 - val_accuracy: 0.8367 - val_loss: 0.4459\n",
      "Epoch 5/50\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 228ms/step - accuracy: 0.9546 - loss: 0.1361 - val_accuracy: 0.8526 - val_loss: 0.4173\n",
      "Epoch 6/50\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 223ms/step - accuracy: 0.9580 - loss: 0.1155 - val_accuracy: 0.8147 - val_loss: 0.4962\n",
      "Epoch 7/50\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 221ms/step - accuracy: 0.9636 - loss: 0.1019 - val_accuracy: 0.8805 - val_loss: 0.3454\n",
      "Epoch 8/50\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 221ms/step - accuracy: 0.9873 - loss: 0.0495 - val_accuracy: 0.9343 - val_loss: 0.2425\n",
      "Epoch 9/50\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 219ms/step - accuracy: 0.9835 - loss: 0.0517 - val_accuracy: 0.9223 - val_loss: 0.3131\n",
      "Epoch 10/50\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 221ms/step - accuracy: 0.9927 - loss: 0.0373 - val_accuracy: 0.7590 - val_loss: 0.8842\n",
      "Epoch 11/50\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 221ms/step - accuracy: 0.9921 - loss: 0.0298 - val_accuracy: 0.9243 - val_loss: 0.2657\n",
      "Epoch 12/50\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 220ms/step - accuracy: 0.9906 - loss: 0.0424 - val_accuracy: 0.9343 - val_loss: 0.2512\n",
      "Epoch 13/50\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 220ms/step - accuracy: 0.9952 - loss: 0.0182 - val_accuracy: 0.9203 - val_loss: 0.2847\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:16:38.599542Z",
     "start_time": "2025-07-24T15:16:38.590203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Model Transfer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_transfer_model(base_name='ResNet50', input_shape=(224,224,3), num_classes=4):\n",
    "    base = getattr(tf.keras.applications, base_name)(\n",
    "        include_top=False, weights='imagenet', input_shape=input_shape, pooling='avg'\n",
    "    )\n",
    "    base.trainable = False\n",
    "\n",
    "    x = layers.Input(shape=input_shape)\n",
    "    y = base(x, training=False)\n",
    "    y = layers.Dense(128, activation='relu')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Dropout(0.5)(y)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(y)\n",
    "\n",
    "    model = models.Model(x, output)\n",
    "    model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n"
   ],
   "id": "8941bc1a7f9a4a44",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:20:40.916038Z",
     "start_time": "2025-07-24T15:16:38.630740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from preprocessing import make_dataset\n",
    "#from model_transfer import build_transfer_model\n",
    "\n",
    "train_ds = make_dataset(os.path.join(BASE,\"train\"), batch=32, augment=True)\n",
    "val_ds   = make_dataset(os.path.join(BASE,\"valid\"), batch=32)\n",
    "\n",
    "model = build_transfer_model('EfficientNetB0')\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    ModelCheckpoint(\"models/transfer_efficientnet.keras\", save_best_only=True)\n",
    "]\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=40, callbacks=callbacks)\n"
   ],
   "id": "b3932ff17cd91ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1695 files belonging to 4 classes.\n",
      "Found 502 files belonging to 4 classes.\n",
      "Epoch 1/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 237ms/step - accuracy: 0.6302 - loss: 1.1127 - val_accuracy: 0.8526 - val_loss: 0.3899\n",
      "Epoch 2/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 186ms/step - accuracy: 0.8063 - loss: 0.5162 - val_accuracy: 0.8247 - val_loss: 0.4436\n",
      "Epoch 3/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 186ms/step - accuracy: 0.8621 - loss: 0.3595 - val_accuracy: 0.8765 - val_loss: 0.3639\n",
      "Epoch 4/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 189ms/step - accuracy: 0.8846 - loss: 0.3308 - val_accuracy: 0.8944 - val_loss: 0.2867\n",
      "Epoch 5/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 185ms/step - accuracy: 0.8914 - loss: 0.2945 - val_accuracy: 0.9024 - val_loss: 0.2898\n",
      "Epoch 6/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 186ms/step - accuracy: 0.9118 - loss: 0.2672 - val_accuracy: 0.9084 - val_loss: 0.2609\n",
      "Epoch 7/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 186ms/step - accuracy: 0.9046 - loss: 0.2624 - val_accuracy: 0.9104 - val_loss: 0.2319\n",
      "Epoch 8/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 184ms/step - accuracy: 0.9193 - loss: 0.2250 - val_accuracy: 0.9084 - val_loss: 0.2693\n",
      "Epoch 9/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 180ms/step - accuracy: 0.9304 - loss: 0.1925 - val_accuracy: 0.9064 - val_loss: 0.2688\n",
      "Epoch 10/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 180ms/step - accuracy: 0.9198 - loss: 0.2093 - val_accuracy: 0.9044 - val_loss: 0.2645\n",
      "Epoch 11/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 180ms/step - accuracy: 0.9355 - loss: 0.1967 - val_accuracy: 0.9104 - val_loss: 0.2584\n",
      "Epoch 12/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 182ms/step - accuracy: 0.9443 - loss: 0.1469 - val_accuracy: 0.9104 - val_loss: 0.2726\n",
      "Epoch 13/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 185ms/step - accuracy: 0.9483 - loss: 0.1481 - val_accuracy: 0.9223 - val_loss: 0.2382\n",
      "Epoch 14/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 188ms/step - accuracy: 0.9437 - loss: 0.1599 - val_accuracy: 0.9203 - val_loss: 0.2246\n",
      "Epoch 15/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 186ms/step - accuracy: 0.9471 - loss: 0.1466 - val_accuracy: 0.9223 - val_loss: 0.2469\n",
      "Epoch 16/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 181ms/step - accuracy: 0.9512 - loss: 0.1434 - val_accuracy: 0.9124 - val_loss: 0.2516\n",
      "Epoch 17/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 181ms/step - accuracy: 0.9514 - loss: 0.1441 - val_accuracy: 0.9283 - val_loss: 0.2316\n",
      "Epoch 18/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 181ms/step - accuracy: 0.9442 - loss: 0.1509 - val_accuracy: 0.9064 - val_loss: 0.2757\n",
      "Epoch 19/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 182ms/step - accuracy: 0.9421 - loss: 0.1622 - val_accuracy: 0.9203 - val_loss: 0.2362\n",
      "Epoch 20/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 187ms/step - accuracy: 0.9622 - loss: 0.1164 - val_accuracy: 0.9263 - val_loss: 0.2358\n",
      "Epoch 21/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 194ms/step - accuracy: 0.9532 - loss: 0.1240 - val_accuracy: 0.9223 - val_loss: 0.2432\n",
      "Epoch 22/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 189ms/step - accuracy: 0.9588 - loss: 0.1214 - val_accuracy: 0.9223 - val_loss: 0.2549\n",
      "Epoch 23/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 191ms/step - accuracy: 0.9574 - loss: 0.1111 - val_accuracy: 0.9183 - val_loss: 0.2401\n",
      "Epoch 24/40\n",
      "\u001B[1m53/53\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 193ms/step - accuracy: 0.9636 - loss: 0.1075 - val_accuracy: 0.9183 - val_loss: 0.2605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3ee5d5dc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:20:40.944711Z",
     "start_time": "2025-07-24T15:20:40.931235Z"
    }
   },
   "cell_type": "code",
   "source": "model.summary()",
   "id": "59809d7ff414bd6e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001B[38;5;33mInputLayer\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m224\u001B[0m, \u001B[38;5;34m224\u001B[0m, \u001B[38;5;34m3\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (\u001B[38;5;33mFunctional\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1280\u001B[0m)           │     \u001B[38;5;34m4,049,571\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │       \u001B[38;5;34m163,968\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │           \u001B[38;5;34m512\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4\u001B[0m)              │           \u001B[38;5;34m516\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m4,544,049\u001B[0m (17.33 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,544,049</span> (17.33 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m164,740\u001B[0m (643.52 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,740</span> (643.52 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m4,049,827\u001B[0m (15.45 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,827</span> (15.45 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m329,482\u001B[0m (1.26 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">329,482</span> (1.26 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:20:40.994906Z",
     "start_time": "2025-07-24T15:20:40.992162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Training and monitoring\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(hist, name):\n",
    "    plt.plot(hist.history['loss'], label='train_loss')\n",
    "    plt.plot(hist.history['val_loss'], label='val_loss')\n",
    "    plt.title(name)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ],
   "id": "3cacfceefc822ba9",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:20:46.124543Z",
     "start_time": "2025-07-24T15:20:40.999502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Evaluation\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "#from preprocessing import make_dataset\n",
    "\n",
    "test_ds = make_dataset(os.path.join(BASE,\"test\"), batch=32, augment=False)\n",
    "model = load_model(\"models/transfer_efficientnet.keras\")\n",
    "y_true = np.concatenate([y for _,y in test_ds], axis=0)\n",
    "y_pred = model.predict(test_ds)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_true, axis=1)\n",
    "\n",
    "print(classification_report(y_true_labels, y_pred_labels, target_names=test_ds.class_names))\n",
    "print(confusion_matrix(y_true_labels, y_pred_labels))\n"
   ],
   "id": "7dd742cbdf4ffcf6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 246 files belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 20:50:42.415947: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 323ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Tumor       0.15      0.14      0.14        49\n",
      "      glioma       0.35      0.39      0.37        80\n",
      "  meningioma       0.24      0.21      0.22        63\n",
      "   pituitary       0.24      0.24      0.24        54\n",
      "\n",
      "    accuracy                           0.26       246\n",
      "   macro avg       0.24      0.24      0.24       246\n",
      "weighted avg       0.26      0.26      0.26       246\n",
      "\n",
      "[[ 7 18 13 11]\n",
      " [10 31 16 23]\n",
      " [20 22 13  8]\n",
      " [11 17 13 13]]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:20:47.259362Z",
     "start_time": "2025-07-24T15:20:46.132410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Evaluation by Custom CNN\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "#from preprocessing import make_dataset\n",
    "\n",
    "test_ds = make_dataset(os.path.join(BASE,\"test\"), batch=32, augment=False)\n",
    "model = load_model(\"models/custom_cnn.keras\")\n",
    "y_true = np.concatenate([y for _,y in test_ds], axis=0)\n",
    "y_pred = model.predict(test_ds)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_true, axis=1)\n",
    "\n",
    "print(classification_report(y_true_labels, y_pred_labels, target_names=test_ds.class_names))\n",
    "print(confusion_matrix(y_true_labels, y_pred_labels))\n"
   ],
   "id": "715614591467e6b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 246 files belonging to 4 classes.\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m1s\u001B[0m 158ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 20:50:46.663090: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 61ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Tumor       0.15      0.14      0.14        49\n",
      "      glioma       0.37      0.38      0.37        80\n",
      "  meningioma       0.27      0.27      0.27        63\n",
      "   pituitary       0.33      0.33      0.33        54\n",
      "\n",
      "    accuracy                           0.29       246\n",
      "   macro avg       0.28      0.28      0.28       246\n",
      "weighted avg       0.29      0.29      0.29       246\n",
      "\n",
      "[[ 7 19 12 11]\n",
      " [15 30 19 16]\n",
      " [17 19 17 10]\n",
      " [ 9 13 14 18]]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:23:04.617166Z",
     "start_time": "2025-07-24T15:23:03.854724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "CLASS_NAMES = [\"glioma\",\"meningioma\",\"no_tumor\",\"pituitary\"]\n",
    "model = load_model(\"models/transfer_efficientnet.keras\")\n",
    "\n",
    "st.title(\"🧠 Brain Tumor MRI Classifier\")\n",
    "uploaded = st.file_uploader(\"Upload an MRI image\", type=[\"png\",\"jpg\",\"jpeg\"])\n",
    "if uploaded:\n",
    "    img = Image.open(uploaded).convert(\"RGB\").resize((224,224))\n",
    "    x = np.array(img)/255.0\n",
    "    preds = model.predict(x[np.newaxis,...])[0]\n",
    "    idx = np.argmax(preds)\n",
    "    st.write(f\"**Prediction:** {CLASS_NAMES[idx]} ({preds[idx]*100:.1f}% confidence)\")\n",
    "    st.bar_chart(preds, use_container_width=True)\n",
    "\n"
   ],
   "id": "227b00738b6569b1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 20:53:04.571 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-24 20:53:04.614 \n",
      "  \u001B[33m\u001B[1mWarning:\u001B[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/dhruvsharma/PyCharmMiscProject/.venv/lib/python3.9/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-07-24 20:53:04.614 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-24 20:53:04.614 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-24 20:53:04.615 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-24 20:53:04.615 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-24 20:53:04.615 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-24 20:53:04.615 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-24 20:53:04.615 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-24 20:53:04.616 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T15:24:55.055877Z",
     "start_time": "2025-07-24T15:24:55.050345Z"
    }
   },
   "cell_type": "code",
   "source": "streamlit run /Users/dhruvsharma/PyCharmMiscProject/.venv/lib/python3.9/site-packages/ipykernel_launcher.py",
   "id": "33c5f8a5de3d969",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2903271827.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[22], line 1\u001B[0;36m\u001B[0m\n\u001B[0;31m    streamlit run /Users/dhruvsharma/PyCharmMiscProject/.venv/lib/python3.9/site-packages/ipykernel_launcher.py\u001B[0m\n\u001B[0m              ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4758e75e6b3c5373"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
